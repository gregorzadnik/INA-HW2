{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter, deque, defaultdict\n",
    "from cdlib.classes import NodeClustering\n",
    "from cdlib import algorithms\n",
    "\n",
    "def draw_graph(G: nx.Graph, **kwargs):\n",
    "    plt.title(G.name)\n",
    "    nx.draw(G, with_labels=True, **kwargs)\n",
    "    plt.show()\n",
    "\n",
    "def read_with_clusters(path):\n",
    "\tG = nx.MultiGraph()\n",
    "\twith open(path, 'r') as file:\n",
    "\t\tline = file.readline()\n",
    "\t\tn = int(line.strip().split(\" \")[1])\n",
    "\t\tfor i in range(n):\n",
    "\t\t\tparts = file.readline().strip().split(\" \")\n",
    "\t\t\tid = int(parts[0])\n",
    "\t\t\tlabel = parts[1]\n",
    "\t\t\tcluster_id = int(parts[2])\n",
    "\t\t\tG.add_node(id, label=label, cluster=cluster_id)\n",
    "\t\tline = file.readline()\n",
    "\t\tm = int(line.strip().split(\" \")[1])\n",
    "\t\tfor _ in range(m):\n",
    "\t\t\tparts = file.readline().strip().split(\" \")\n",
    "\t\t\tG.add_edge(int(parts[0]), int(parts[1]))\n",
    "\t\t\t\n",
    "\treturn G\n",
    "\n",
    "def distance(G, i):\n",
    "\tD = [-1] * len(G) # D = {}\n",
    "\tQ = deque()\n",
    "\tD[i] = 0\n",
    "\tQ.append(i)\n",
    "\twhile Q:\n",
    "\t\ti = Q.popleft()\n",
    "\t\tfor j in G[i]:\n",
    "\t\t\tif D[j] == -1: # if j not in D:\n",
    "\t\t\t\tD[j] = D[i] + 1\n",
    "\t\t\t\tQ.append(j)\n",
    "\treturn [d for d in D if d > 0]\n",
    "\n",
    "def distances(G, n = 100):\n",
    "\tD = []\n",
    "\tapprox = G.nodes()\n",
    "\tif len(G) > n:\n",
    "\t\tapprox = random.sample(list(G.nodes()), n)\n",
    "\tfor i in approx:\n",
    "\t\tD.append(distance(G, i))\n",
    "\treturn D\n",
    "\n",
    "def lcc(G: nx.Graph) -> float:\n",
    "    \"\"\"relative size of the largest connected component (between 0 and 1)\"\"\"\n",
    "    if G.is_directed(): G = nx.Graph(G)\n",
    "\n",
    "    return len(max(nx.connected_components(G), key=len)) / len(G)\n",
    "\n",
    "def distribution(G):\n",
    "\tdegrees = np.array(sorted([G.degree(n) for n in G.nodes()], reverse=True))\n",
    "\tcount_general = Counter(degrees)\n",
    "\tfig = plt.figure()\n",
    "\tplt.xscale(\"log\")\n",
    "\tplt.yscale(\"log\")\n",
    "\tgeneral_dist = plt.scatter(count_general.keys(), count_general.values(), label=\"Degrees\", s=20)\n",
    "\tplt.xlabel(\"k\")\n",
    "\tplt.ylabel(\"p(k)\")\n",
    "\tplt.legend()\n",
    "\tplt.title(G.name)\n",
    "\tplt.show()\n",
    "\tplt.savefig(f\"{G.name}\")\n",
    "\n",
    "def info(G):\n",
    "\tprint(\"{:>20s} | '{:s}'\".format('Graph', G.name))\n",
    "\tn = G.number_of_nodes()\n",
    "\tprint(\"{:>20s} | {:,d}\".format('Nodes', n))\n",
    "\tm = G.number_of_edges()\n",
    "\tprint(\"{:>20s} | {:,d}\".format('Edges', m))\n",
    "\tk = 2*m/n\n",
    "\tprint(\"{:>20s} | {:.2f}\".format('Degree', k))\n",
    "\tmax_degree = max([G.degree(n) for n in G.nodes()])\n",
    "\tprint(\"{:>20s} | {:.2f}\".format('Max node degree', max_degree))\n",
    "\tcc = lcc(G)\n",
    "\tprint(\"{:>20s} | {:.2f}\".format('LCC', cc))\n",
    "\tG2 = G\n",
    "\tif type(G2) == nx.MultiGraph:\n",
    "\t\tG2 = nx.Graph(G)\n",
    "\tdis = [i for d in distances(G2) for i in d]\n",
    "\tprint(\"{:>20s} | {:.2f} ({:,d})\".format('Distance', sum(dis) / len(dis), max(dis)))\n",
    "\tdensity = k/(n-1)\n",
    "\tprint(\"{:>20s} | {:.9f}\".format('Density', density))\n",
    "\tclustering = nx.average_clustering(G)\n",
    "\tprint(\"{:>20s} | {:.9f}\".format('Clustering', clustering))\n",
    "\tdistribution(G)\n",
    "\n",
    "def top_nodes(G: nx.Graph, C: dict[any, float], centrality: str, n=15) -> dict[any]:\n",
    "    \"\"\"prints and returns top n nodes by given measure of centrality\"\"\"\n",
    "\n",
    "    # OPT take callable instead of dict, only compute centrality on non-mode nodes\n",
    "    # OPT np.argpartition instead of sort\n",
    "    print(\"{:>12s} | '{:s}'\".format('Centrality', centrality))\n",
    "    nodes = []\n",
    "    for i, c in sorted(C.items(), key=lambda item: (item[1], G.degree[item[0]]), reverse=True):\n",
    "        if not G.nodes[i]['label'].startswith('m-'):\n",
    "            nodes.append(G.nodes[i])\n",
    "            print(\"{:>12.6f} | '{:s}' ({:,d})\".format(\n",
    "                c, G.nodes[i]['label'], G.degree[i]))\n",
    "            n -= 1\n",
    "            if n == 0:\n",
    "                break\n",
    "    print()\n",
    "    return nodes\n",
    "def actor_names(nodes) -> list[str]:\n",
    "    \"\"\"Parses labels of nodes in collaboration_imdb.net into\n",
    "    a nicer format. Try pasting the ouput of this function into\n",
    "    chatGPT if you have trouble classifying the actors.\"\"\"\n",
    "    names = []\n",
    "    for n in nodes:\n",
    "        try:\n",
    "            last, fst = n[\"label\"].split(\", \")\n",
    "            if fst[-1] == ')':\n",
    "                fst = fst[:fst.index('(') - 1]\n",
    "\n",
    "            names.append(f\"{fst} {last}\")\n",
    "        except ValueError: # failed unpacking\n",
    "            names.append(n[\"label\"])\n",
    "\n",
    "    return names\n",
    "def random_walk(G):\n",
    "\tn = G.number_of_nodes()\n",
    "\tvisited = set([])\n",
    "\tcurrent = random.sample(list(G.nodes()), 1)[0]\n",
    "\twhile len(visited)/n < 0.15:\n",
    "\t\tvisited.add(current)\n",
    "\t\tcurrent = random.sample(list(G[current]), 1)[0]\n",
    "\treturn nx.convert_node_labels_to_integers(nx.Graph(nx.induced_subgraph(G, visited)))\n",
    "\n",
    "def eigenvector_centrality(G, eps = 1e-6):\n",
    "    # Initialize eigenvector centrality score\n",
    "    E = [1] * G.number_of_nodes()\n",
    "    diff = 1\n",
    "    # Repeat until the change in scores is less than a small value 'eps'\n",
    "    while diff > eps:\n",
    "        # Update scores based on neighbors' scores\n",
    "        U = [sum([E[j] for j in G[i]]) for i in G.nodes()]\n",
    "        # Normalize scores\n",
    "        u = sum(U)\n",
    "        U = [U[i] * len(G) / u for i in G.nodes()]\n",
    "        # Calculate change in scores\n",
    "        diff = sum([abs(E[i] - U[i]) for i in G.nodes()])\n",
    "        # Use the new scores for the next iteration\n",
    "        E = U\n",
    "    return {i: E[i] for i in range(len(E))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prva naloga\n",
    "G = nx.convert_node_labels_to_integers(read_with_clusters(\"dolphins.net\"), label_attribute=None)\n",
    "#degree_centrality = top_nodes(G, nx.degree_centrality(G), 'centrality')\n",
    "#clustering = top_nodes(G, nx.clustering(G), 'clustering')\n",
    "\n",
    "#mi_corrected_clustering = {i: c * (G.degree(i) - 1) for i, c in nx.clustering(G).items()}\n",
    "#mi_corrected(G, mi_corrected_clustering, 'mi corrected clustering')\n",
    "#pagerank_cent = top_nodes(G, nx.pagerank(G), 'pagerank')\n",
    "#closeness_cent = top_nodes(G, nx.closeness_centrality(G), 'closeness')\n",
    "betweenness_cent = top_nodes(G, nx.betweenness_centrality(G), 'betweenness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(G, i):\n",
    "\tD = [-1] * len(G) # D = {}\n",
    "\tQ = deque()\n",
    "\tD[i] = 0\n",
    "\tQ.append(i)\n",
    "\twhile Q:\n",
    "\t\ti = Q.popleft()\n",
    "\t\tfor j in G[i]:\n",
    "\t\t\tif D[j] == -1: # if j not in D:\n",
    "\t\t\t\tD[j] = D[i] + 1\n",
    "\t\t\t\tQ.append(j)\n",
    "\treturn [d for d in D if d > 0]\n",
    "def distances(G, n = 100):\n",
    "\tD = []\n",
    "\tapprox = G.nodes()\n",
    "\tif len(G) > n:\n",
    "\t\tapprox = random.sample(list(G.nodes()), n)\n",
    "\tfor i in approx:\n",
    "\t\tD.append(distance(G, i))\n",
    "\treturn D\n",
    "def distribution(G):\n",
    "\tdegrees = np.array(sorted([G.degree(n) for n in G.nodes()], reverse=True))\n",
    "\tcount_general = Counter(degrees)\n",
    "\tfig = plt.figure()\n",
    "\tplt.xscale(\"log\")\n",
    "\tplt.yscale(\"log\")\n",
    "\tgeneral_dist = plt.scatter(count_general.keys(), count_general.values(), label=\"Degrees\", s=20)\n",
    "\tplt.xlabel(\"k\")\n",
    "\tplt.ylabel(\"p(k)\")\n",
    "\tplt.legend()\n",
    "\tplt.title(G.name)\n",
    "\tplt.show()\n",
    "\tplt.savefig(f\"{G.name}\")\n",
    "def info(G):\n",
    "\tprint(\"{:>20s} | '{:s}'\".format('Graph', G.name))\n",
    "\tn = G.number_of_nodes()\n",
    "\tprint(\"{:>20s} | {:,d}\".format('Nodes', n))\n",
    "\tm = G.number_of_edges()\n",
    "\tprint(\"{:>20s} | {:,d}\".format('Edges', m))\n",
    "\tk = 2*m/n\n",
    "\tprint(\"{:>20s} | {:.2f}\".format('Degree', k))\n",
    "\tmax_degree = max([G.degree(n) for n in G.nodes()])\n",
    "\tprint(\"{:>20s} | {:.2f}\".format('Max node degree', max_degree))\n",
    "\tcc = lcc(G)\n",
    "\tprint(\"{:>20s} | {:.2f}\".format('LCC', cc))\n",
    "\tG2 = G\n",
    "\tif type(G2) == nx.MultiGraph:\n",
    "\t\tG2 = nx.Graph(G)\n",
    "\tdis = [i for d in distances(G2) for i in d]\n",
    "\tprint(\"{:>20s} | {:.2f} ({:,d})\".format('Distance', sum(dis) / len(dis), max(dis)))\n",
    "\tdensity = k/(n-1)\n",
    "\tprint(\"{:>20s} | {:.9f}\".format('Density', density))\n",
    "\tclustering = nx.average_clustering(G)\n",
    "\tprint(\"{:>20s} | {:.9f}\".format('Clustering', clustering))\n",
    "\tdistribution(G)\n",
    "def random_walk(G):\n",
    "\tn = G.number_of_nodes()\n",
    "\tvisited = set([])\n",
    "\tcurrent = random.sample(list(G.nodes()), 1)[0]\n",
    "\twhile len(visited)/n < 0.15:\n",
    "\t\tvisited.add(current)\n",
    "\t\tcurrent = random.sample(list(G[current]), 1)[0]\n",
    "\treturn nx.convert_node_labels_to_integers(nx.Graph(nx.induced_subgraph(G, visited)))\n",
    "network =  'social'\n",
    "file = f\"{network}.net\"\n",
    "G = nx.Graph(nx.convert_node_labels_to_integers(nx.read_pajek(file)))\n",
    "G.name = \"Original social network\"\n",
    "info(G)\n",
    "SG = nx.Graph(random_walk(G))\n",
    "SG.name = \"Induced social network\"\n",
    "info(SG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_gn(mi = 0.1):\n",
    "    G = nx.MultiGraph(name=\"girvan_newman\")\n",
    "    for i in range(72):\n",
    "        G.add_node(i, cluster=i // 24 + 1)\n",
    "    for i in range(72):\n",
    "        for j in range(i+1, 72):\n",
    "            if G.nodes[i]['cluster'] == G.nodes[j]['cluster']:\n",
    "                if random.random() < 20*(1-mi)/23:\n",
    "                    G.add_edge(i,j)\n",
    "            else:\n",
    "                if random.random() < 5*mi/18:\n",
    "                    G.add_edge(i,j)\n",
    "    return G\n",
    "\n",
    "def known_clustering(G: nx.Graph, cluster_attr=\"value\") -> NodeClustering:\n",
    "    \"\"\"Extracts known node clustering from their attrubute with supplied name.\"\"\"\n",
    "\n",
    "    C = defaultdict(list)\n",
    "    for i, d in G.nodes(data=True):\n",
    "        C[d[cluster_attr]].append(i)\n",
    "\n",
    "    return NodeClustering(list(C.values()), G, \"Known\")\n",
    "    #return list(C.values())\n",
    "\n",
    "\n",
    "def CD_comparison(G: nx.Graph, algs, runs=1) -> None:\n",
    "    \"\"\"Compare quality of community-detection algorithms on G.\n",
    "    Algorithms must conform to the cdlib format (returning a NodeClustering object).\"\"\"\n",
    "    K = known_clustering(G)\n",
    "\n",
    "    print(\"{:>12s} | {:5s} {:^6s}  {:^5s}  {:^5s}  {:^5s}\".format(\n",
    "        'Algorithm', 'Count', 'Q', 'NMI', 'ARI', 'VI'))\n",
    "\n",
    "    for alg in algs:\n",
    "        s, Q, NMI, ARI, VI = 0, 0, 0, 0, 0\n",
    "\n",
    "        for _ in range(runs):\n",
    "            C = algs[alg](G)\n",
    "            s += len(C.communities) / runs # C.communities is a list of lists of node IDs\n",
    "            Q += C.newman_girvan_modularity().score / runs\n",
    "            NMI += K.normalized_mutual_information(C).score / runs\n",
    "            ARI += K.adjusted_rand_index(C).score / runs\n",
    "            VI += K.variation_of_information(C).score / runs\n",
    "\n",
    "        print(\"{:>12s} | {:>5.0f} {:6.3f}  {:5.3f}  {:5.3f}  {:5.3f}\".format(\n",
    "            '\\'' + alg + '\\'', s, Q, NMI, ARI, VI))\n",
    "    print()\n",
    "\n",
    "\n",
    "def fast_label_propagation(G):\n",
    "    assert (type(G) == nx.MultiGraph)\n",
    "\n",
    "    N = list(G.nodes())\n",
    "    random.shuffle(N)\n",
    "\n",
    "    Q = deque(N)\n",
    "    S = [True] * len(G)\n",
    "\n",
    "    C = [i for i in range(len(G))]\n",
    "\n",
    "    while Q:\n",
    "        i = Q.popleft()\n",
    "        S[i] = False\n",
    "\n",
    "        if len(G[i]) > 0:\n",
    "            L = {}\n",
    "            for j in G[i]:\n",
    "                if C[j] not in L:\n",
    "                    L[C[j]] = 0\n",
    "                L[C[j]] += len(G[i][j])\n",
    "\n",
    "            maxl = max(L.values())\n",
    "            c = random.choice([c for c in L if L[c] == maxl])\n",
    "\n",
    "            if C[i] != c:\n",
    "                C[i] = c\n",
    "\n",
    "                for j in G[i]:\n",
    "                    if C[j] != c and not S[j]:\n",
    "                        Q.append(j)\n",
    "                        S[j] = True\n",
    "\n",
    "    L = {}\n",
    "    for i in N:\n",
    "        if C[i] in L:\n",
    "            L[C[i]].append(i)\n",
    "        else:\n",
    "            L[C[i]] = [i]\n",
    "\n",
    "    return NodeClustering(list(L.values()), G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 25\n",
    "algs = {\"Infomap\": algorithms.infomap, \"Louvain\": algorithms.louvain,\n",
    "        \"FLPA\": fast_label_propagation}\n",
    "res = {alg: [] for alg in algs.keys()}\n",
    "mis = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "plt.figure()\n",
    "for alg in algs:\n",
    "    for mi in mis:\n",
    "        nmi = 0\n",
    "        for _ in range(iters):\n",
    "            G = nx.MultiGraph(generate_gn(mi))\n",
    "            K = known_clustering(G, cluster_attr='cluster')\n",
    "            C = algs[alg](G)\n",
    "            nmi += K.normalized_mutual_information(C).score\n",
    "        nmi /= iters\n",
    "        res[alg].append(nmi)\n",
    "    plt.plot(mis, res[alg], label=alg)\n",
    "\n",
    "plt.xlabel('$\\mu$')\n",
    "plt.ylabel('NMI')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 25\n",
    "algs = {\"FLPA\": fast_label_propagation, \"Infomap\": algorithms.infomap, \"Louvain\": algorithms.louvain}\n",
    "res = {alg: [] for alg in algs.keys()}\n",
    "mis = [\"00\", \"02\", \"04\", \"06\", \"08\"]\n",
    "\n",
    "plt.figure()\n",
    "for alg in algs:\n",
    "    for mi in mis:\n",
    "        nmi = 0\n",
    "        for i in range(iters):\n",
    "            netpath = f\"WHOLE/LFR_{mi}_{i}.net\"\n",
    "            print(netpath)\n",
    "            G = nx.convert_node_labels_to_integers(read_with_clusters(netpath))\n",
    "            K = known_clustering(G, cluster_attr='cluster')\n",
    "            C = algs[alg](G)\n",
    "            nmi += K.normalized_mutual_information(C).score\n",
    "        nmi /= iters\n",
    "        res[alg].append(nmi)\n",
    "    plt.plot(mis, res[alg], label=alg)\n",
    "\n",
    "plt.xlabel('$\\mu$')\n",
    "plt.ylabel('NMI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iters = 25\n",
    "n = 1000\n",
    "algs = {\"FLPA\": fast_label_propagation, \"Infomap\": algorithms.infomap, \"Louvain\": algorithms.louvain}\n",
    "res = {alg: [] for alg in algs.keys()}\n",
    "degrees = [8, 16, 24, 32, 40]\n",
    "\n",
    "plt.figure()\n",
    "for alg in algs:\n",
    "    for deg in degrees:\n",
    "        print(f\"{alg}, {deg}\")\n",
    "        nvi = 0\n",
    "        for i in range(iters):\n",
    "            G = nx.MultiGraph(nx.gnm_random_graph(n, deg*n/2))\n",
    "            cc = nx.connected_components(G)\n",
    "            K = NodeClustering(list(cc), G)\n",
    "            #K = known_clustering(G, cluster_attr='cluster')\n",
    "            C = algs[alg](G)\n",
    "            nvi += K.variation_of_information(C).score / np.log(n)\n",
    "        nvi /= iters\n",
    "        res[alg].append(nvi)\n",
    "    plt.plot(degrees, res[alg], label=alg)\n",
    "\n",
    "plt.xlabel('Average degree')\n",
    "plt.ylabel('NVI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peta\n",
    "G = nx.Graph(nx.convert_node_labels_to_integers(read_with_clusters('aps_2008_2013.net')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_label_propagation(G):\n",
    "    assert (type(G) == nx.MultiGraph)\n",
    "    N = list(G.nodes())\n",
    "    random.shuffle(N)\n",
    "    Q = deque(N)\n",
    "    S = [True] * len(G)\n",
    "    C = [i for i in range(len(G))]\n",
    "    while Q:\n",
    "        i = Q.popleft()\n",
    "        S[i] = False\n",
    "\n",
    "        if len(G[i]) > 0:\n",
    "            L = {}\n",
    "            for j in G[i]:\n",
    "                if C[j] not in L:\n",
    "                    L[C[j]] = 0\n",
    "                L[C[j]] += len(G[i][j])\n",
    "            maxl = max(L.values())\n",
    "            c = random.choice([c for c in L if L[c] == maxl])\n",
    "            if C[i] != c:\n",
    "                C[i] = c\n",
    "\n",
    "                for j in G[i]:\n",
    "                    if C[j] != c and not S[j]:\n",
    "                        Q.append(j)\n",
    "                        S[j] = True\n",
    "    L = {}\n",
    "    for i in N:\n",
    "        if C[i] in L:\n",
    "            L[C[i]].append(i)\n",
    "        else:\n",
    "            L[C[i]] = [i]\n",
    "\n",
    "    return list(L.values())\n",
    "\n",
    "G13 = [i for i in range(len(G)) if G.nodes()[i]['label'].endswith('-2013\"')]\n",
    "MG = nx.MultiGraph(G)\n",
    "C = fast_label_propagation(MG)\n",
    "print(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc = algorithms.infomap(G)\n",
    "print(kc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for node in G13:\n",
    "    right_cluster = []\n",
    "    for c in C.communities:\n",
    "        if node in c:\n",
    "            right_cluster = c\n",
    "            break\n",
    "    journals = [G.nodes()[n]['cluster'] for n in right_cluster if not G.nodes()[n]['label'].endswith('-2013\"')]\n",
    "    most = Counter(journals).most_common()\n",
    "    if len(most) == 0:\n",
    "        most = [(random.randint(1,10), 0)]\n",
    "    predicted = G.nodes()[node]['cluster']\n",
    "    if most[0][0] == predicted:\n",
    "        correct += 1\n",
    "acc = correct*100/len(G13)\n",
    "print(f\"Accuracy: {acc}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C = algorithms.label_propagation(G)\n",
    "def get_neighbourhood(G, node, level=3):\n",
    "    neighbourhood = set()\n",
    "    queue = deque([node])\n",
    "    for _ in range(level):\n",
    "        current = deque()\n",
    "        while queue:\n",
    "            current.extend([n for n in G[queue.popleft()]])\n",
    "        while current:\n",
    "            n = current.popleft()\n",
    "            if n not in neighbourhood:\n",
    "                neighbourhood.add(n)\n",
    "                queue.append(n)\n",
    "    return list(neighbourhood)\n",
    "\n",
    "G = nx.Graph(nx.convert_node_labels_to_integers(read_with_clusters('aps_2008_2013.net')))\n",
    "G13 = [i for i in range(len(G)) if G.nodes()[i]['label'].endswith('-2013\"')]\n",
    "iters = 10\n",
    "accuracies = []\n",
    "for i in range(iters):\n",
    "    correct = 0\n",
    "    print(f\"Iteration {i}\")\n",
    "    for node in G13:\n",
    "        right_cluster = get_neighbourhood(G, node, level=2)\n",
    "        journals = [G.nodes()[n]['cluster'] for n in right_cluster if not G.nodes()[n]['label'].endswith('-2013\"')]\n",
    "        most = Counter(journals).most_common()\n",
    "        if len(most) == 0:\n",
    "            most = [(random.randint(1,10), 0)]\n",
    "        predicted = G.nodes()[node]['cluster']\n",
    "        if most[0][0] == predicted:\n",
    "            correct += 1\n",
    "    acc = correct*100/len(G13)\n",
    "    print(f\"Accuracy: {acc}%\")\n",
    "    accuracies.append(acc)\n",
    "print(accuracies)\n",
    "print(sum(accuracies)/len(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "3.9101632409913716\n",
      "0.0009777508174543504\n"
     ]
    }
   ],
   "source": [
    "# Sesta\n",
    "def pai(G, i, j, *kwargs):\n",
    "    return len(G[i]) * len(G[j])\n",
    "\n",
    "def aai(G, i, j, *kwargs):\n",
    "    nbhd = set(G[i]).union(set(G[j]))\n",
    "    return sum([1/np.log(len(G[node])) for node in nbhd])\n",
    "\n",
    "def lci(G, i, j, C):\n",
    "    ci = C[0]\n",
    "    cj = C[0]\n",
    "    for c in C:\n",
    "        if i in c:\n",
    "            ci = c\n",
    "            break\n",
    "    for c in C:\n",
    "        if j in c:\n",
    "            cj = c\n",
    "            break\n",
    "    if ci != cj:\n",
    "        return 0\n",
    "    nc = len(ci)\n",
    "    SG = nx.induced_subgraph(G, cj)\n",
    "    mc = SG.number_of_edges()\n",
    "    return 2*mc/(nc*(nc-1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "C = algorithms.leiden(G)\n",
    "i = 2996\n",
    "j = 186\n",
    "print(pai(G, i, j, C.communities))\n",
    "print(aai(G, i, j, C.communities))\n",
    "print(lci(G, i, j, C.communities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "3.9101632409913716\n",
      "0.0009789350863778081\n",
      "42926\n",
      "429267\n",
      "386341\n"
     ]
    }
   ],
   "source": [
    "i = 2996\n",
    "j = 186\n",
    "print(pai(G, i, j))\n",
    "print(aai(G, i, j))\n",
    "print(lci(G, i, j, C.communities))\n",
    "\n",
    "\n",
    "def framework(G2: nx.Graph, s):\n",
    "    G = nx.Graph(G2)\n",
    "    nodes = list(G)\n",
    "    m = G.number_of_edges()\n",
    "    Ln = set()\n",
    "    while len(Ln) < m//10:\n",
    "        i, j = random.sample(nodes, 2)\n",
    "        if i not in G[j] and (i,j) not in Ln and (j, i) not in Ln:\n",
    "            Ln.add((i,j))\n",
    "    edges = list(G.edges)\n",
    "    Lp = set(random.sample(edges, m//10))\n",
    "    G.remove_edges_from(Lp)\n",
    "    union = Ln.union(Lp)\n",
    "\n",
    "    results = {}\n",
    "    C = []\n",
    "    if s == lci:\n",
    "        C = algorithms.leiden(G2)\n",
    "    for i, j in union:\n",
    "        \n",
    "        \n",
    "\n",
    "RG = nx.Graph(G)\n",
    "framework(RG, pai)\n",
    "print(G.number_of_edges())\n",
    "print(RG.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 45224)\n"
     ]
    }
   ],
   "source": [
    "print(list(G.edges())[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
